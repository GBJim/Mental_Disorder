{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from urllib.request import urlopen\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentiment_analyize(tweets):\n",
    "    payload = {\"data\": [],\"language\": \"en\"}\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        payload[\"data\"].append({\"text\": tweet[\"text\"],\"id\": tweet[\"id\"]})\n",
    "    \n",
    "    payload = json.dumps(payload).encode('utf-8')\n",
    "    response = urlopen('http://www.sentiment140.com/api/bulkClassifyJson?appid=ccha97u@gmail.com', payload) # request to server\n",
    "    results = response.read().decode('\"ISO-8859-1\"') # get the response\n",
    "    results = json.loads(results)['data']\n",
    "    for i,result in enumerate(results):\n",
    "       \n",
    "        if result['polarity'] == 0:\n",
    "            tweets[i][\"polarity\"] = \"negative\"\n",
    "        elif result['polarity'] == 2:\n",
    "            tweets[i][\"polarity\"] = \"neutral\"\n",
    "        elif result['polarity'] == 4:\n",
    "            tweets[i][\"polarity\"] = \"positive\"\n",
    "        else:\n",
    "             tweets[i][\"polarity\"] = \"unknown\"\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def scan_tweets(tweets, bulk_size=4000):\n",
    "\n",
    "    buffer = []\n",
    "    sentiment_tweets = []\n",
    "    for tweet in tweets:\n",
    "        buffer.append(tweet)\n",
    "        if len(buffer) >= bulk_size:\n",
    "            print(\"4000 tweets processed\")\n",
    "            sentiment_tweets += sentiment_analyize(buffer)\n",
    "            buffer = []\n",
    "    \n",
    "    \n",
    "    sentiment_tweets += sentiment_analyize(buffer)\n",
    "    \n",
    "    return sentiment_tweets\n",
    "\n",
    "\n",
    "\n",
    "def scan_db(collectionName,dbName='idea', bulk_size=4000):\n",
    "    collection = MongoClient('localhost',27017)[dbName][collectionName]\n",
    "    buffer = []\n",
    "    sentiment_tweets = []\n",
    "    for tweet in collection.find():\n",
    "        buffer.append(tweet)\n",
    "        if len(buffer) >= bulk_size:\n",
    "            print(\"4000 tweets processed\")\n",
    "            sentiment_tweets += sentiment_analyize(buffer)\n",
    "            buffer = []\n",
    "    \n",
    "    \n",
    "    sentiment_tweets += sentiment_analyize(buffer)\n",
    "    \n",
    "    return sentiment_tweets\n",
    "    \n",
    "def writeUsers(tweets, collectionName):\n",
    "\tcollection = MongoClient(\"localhost\", 27017)[\"idea\"][collectionName]\n",
    "\tcollection.insert(tweets)\n",
    "\tprint(\"{} tweets inserted\".format(len(tweets)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n",
      "4000 tweets processed\n"
     ]
    }
   ],
   "source": [
    "tweets = scan_db(\"BPD_581_emotion_backup\",bulk_size=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
