{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import operator\n",
    "from scipy.spatial import distance\n",
    "from Levenshtein import *\n",
    "import re\n",
    "%matplotlib inline\n",
    "import age_gender_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Preprocessing functions:\n",
    "\n",
    "\n",
    "\n",
    "def stringConditionProcess(group, method = \"first\"):\n",
    "    result = []\n",
    "    for timeSeries in group:\n",
    "        conditions = seriesContains(timeSeries, method)\n",
    "        result.append(timeSeries[conditions])\n",
    "    return result\n",
    "\n",
    "def getUsersPolarities(dbName,collectionName):\n",
    "    collection = MongoClient(\"localhost\", 27017)[dbName][collectionName]\n",
    "    usersPolarties = {}\n",
    "    for tweet in collection.find():\n",
    "        userID = tweet[\"user\"][\"id\"]\n",
    "        if tweet[\"polarity\"] == \"positive\":\n",
    "            polarity = 1\n",
    "        elif tweet[\"polarity\"] == \"negative\":\n",
    "            polarity = -1\n",
    "        else:\n",
    "            polarity = 0\n",
    "   \n",
    "            \n",
    "        date = tweet[\"created_at\"]\n",
    "        text = tweet['text']\n",
    "\n",
    "        if userID not in usersPolarties:\n",
    "            usersPolarties[userID] = {}\n",
    "        if date not in usersPolarties[userID]:\n",
    "            usersPolarties[userID][date] = {}\n",
    "        usersPolarties[userID][date]['text'] = text\n",
    "        usersPolarties[userID][date]['polarity'] =  polarity\n",
    "\n",
    "\n",
    "    return usersPolarties\n",
    "\n",
    "\n",
    "def timeSeriesTransform(usersEmotions):\n",
    "    for userID in usersEmotions:\n",
    "        usersEmotions[userID] = pd.DataFrame.from_dict(usersEmotions[userID], orient='index').fillna(0)\n",
    "        usersEmotions[userID]['dt'] = np.zeros(usersEmotions[userID].shape[0],dtype=float)\n",
    "        usersEmotions[userID].loc[:-1,'dt'] = (usersEmotions[userID].index[1:].values - usersEmotions[userID].index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return list(usersEmotions.values())\n",
    "\n",
    "\n",
    "def disambiguate(timeSeries):\n",
    "    conditions = np.logical_not(timeSeries['ambiguous'].values)\n",
    "    timeSeries = timeSeries[conditions]\n",
    "    timeSeries['dt'] = np.zeros(timeSeries.shape[0],dtype=float)\n",
    "    timeSeries.loc[:-1,'dt'] = (timeSeries.index[1:].values - timeSeries.index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return timeSeries\n",
    "        \n",
    "def invalid_removal(data):\n",
    "    data = np.array(data)\n",
    "    return data[np.isfinite(data)]\n",
    "    \n",
    "def reject_outliers(data, m=2):\n",
    "    data = np.array(data)\n",
    "    data = data[np.isfinite(data)]\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#computational functions\n",
    "\n",
    "def getAge(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_age(texts)\n",
    "\n",
    "def getGender(timeSeries):\n",
    "    texts = \"\"\n",
    "    for text in timeSeries[\"text\"].values:\n",
    "        texts += text + \"\\n\"\n",
    "    return age_gender_predictor.get_gender(texts)\n",
    "def negative_counter(timeSeries):\n",
    "    return timeSeries[\"polarity\"].values == -1\n",
    "def positive_counter(timeSeries):\n",
    "    return timeSeries[\"polarity\"].values == 1\n",
    "\n",
    "def comboTracker(timeSeries, attribute= \"polarity\"):\n",
    "    array = timeSeries[attribute]\n",
    "    starter = array[0]\n",
    "    combo = 1\n",
    "    result = []\n",
    "    for cursor in array[1:]:\n",
    "        if starter == cursor:\n",
    "            combo += 1\n",
    "        else:\n",
    "            if combo > 1:\n",
    "                result.append((starter, combo))\n",
    "            starter = cursor\n",
    "            combo = 1\n",
    "    if combo > 1:\n",
    "         result.append((starter, combo))\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def seriesContains(timeSeries,method =\"first\"):\n",
    "    if method == \"first\":\n",
    "        match_function = np.vectorize(firstPronuonDetect)\n",
    "    elif method == \"second\":\n",
    "        match_function = np.vectorize(secondPronuonDetect)\n",
    "    elif method == \"third\":\n",
    "            match_function = np.vectorize(thirdPronuonDetect)\n",
    "\n",
    "\n",
    "    return match_function(timeSeries[\"text\"].str.lower().str.split().values)\n",
    "    \n",
    "\n",
    "\n",
    "def thirdPronuonDetect(words, matcher=re.compile(\"@[a-z]+\")):\n",
    "    for word in words:\n",
    "        if word == \"@\":\n",
    "            continue\n",
    "        elif matcher.search(word):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "    \n",
    "def secondPronuonDetect(words, matchers=[\"you\"]):\n",
    "    for matcher in matchers:\n",
    "        if matcher in words:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "\n",
    "def firstPronuonDetect(words, matchers=[\"i\",\"we\",\"i'd\",\"i'm\"]):\n",
    "    for matcher in matchers:\n",
    "        if matcher in words:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def getFlipsDurationMean(timeSeries, upperbound=np.inf, lowerbound=0):\n",
    "    flips = getFlips(timeSeries)\n",
    "    durations = getFlipsDuration(timeSeries, flips)\n",
    "    durations = durations[np.isfinite(durations)]\n",
    "    durations = durations[(durations > lowerbound) & (durations < upperbound)]\n",
    "    return np.mean(durations)\n",
    "    \n",
    "    \n",
    "    \n",
    "def getFlipsDuration(timeSeries, flips):\n",
    "    timeSeries = timeSeries[flips]\n",
    "    timeSeries.loc[:,'dt'] = np.zeros(timeSeries.shape[0],dtype=float)\n",
    "    timeSeries.loc[:-1,'dt'] = (timeSeries.index[1:].values - timeSeries.index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return timeSeries['dt'][:-1].values\n",
    "\n",
    "\n",
    "\n",
    "def getFlips(timeSeries, attribute= 'polarity'):\n",
    "    flips = np.zeros(timeSeries.shape[0],dtype=bool)\n",
    "    polarity = timeSeries[attribute].values[:-1]\n",
    "    right_elements = timeSeries[attribute].values[1:]\n",
    "    flips[:-1] = (polarity * right_elements) < 0\n",
    "    return flips\n",
    "\n",
    "\n",
    "def userVerify(timeSeries, threshold = 0.5):\n",
    "    http_rows = getHTTPRows(timeSeries)\n",
    "    average_http_count = np.sum(http_rows) / timeSeries.shape[0]\n",
    "    return (average_http_count < threshold) & (timeSeries.shape[0] > 100)\n",
    " \n",
    "\n",
    "def groupFilter(group):\n",
    "    new_group = []\n",
    "    for timeSeries in group:\n",
    "        if userVerify(timeSeries):\n",
    "            new_group.append(timeSeries)\n",
    "    return new_group\n",
    "\n",
    "\n",
    "\n",
    "def cleanPost(timeSeries):\n",
    "    left_text = timeSeries['text'].values[:-1]\n",
    "    right_text = timeSeries['text'].values[1:]\n",
    "    conditions = np.ones(timeSeries.shape[0],dtype=bool)\n",
    "    edit_distance = np.vectorize(distance)\n",
    "    conditions[:-1] =  conditions[:-1] & (edit_distance(left_text, right_text) > 5)\n",
    "    patterns = ['http://','https://']\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        conditions = conditions & np.logical_not(timeSeries['text'].str.contains(pattern).values)\n",
    "    timeSeries = timeSeries[conditions]\n",
    "    timeSeries.loc[:,'dt'] = np.zeros(timeSeries.shape[0],dtype=float)\n",
    "    timeSeries.loc[:-1,'dt'] = (timeSeries.index[1:].values - timeSeries.index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "\n",
    "    return timeSeries\n",
    "\n",
    "def getHTTPRows(timeSeries):\n",
    "    count = 0\n",
    "    patterns = ['http://','https://']\n",
    "    conditions = timeSeries['text'].str.contains(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        conditions = conditions | timeSeries['text'].str.contains(pattern)\n",
    "\n",
    "    return conditions.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plotting functions \n",
    "\n",
    "def agePlot(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    for g,group in enumerate(groups):\n",
    "        ages = np.zeros(len(group),dtype=float)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            age = getAge(timeSeries)\n",
    "            ages[i] = age\n",
    "        plt.hist(ages,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('User Count')\n",
    "        plt.xlabel('Age(years)')\n",
    "        plt.title(legends[g])\n",
    "        plt.show()\n",
    "        print(\"Age mean:{0:2f} STD:{1:2f}\".format(np.mean(ages),np.std(ages)))\n",
    " \n",
    "def genderPlot(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    for g,group in enumerate(groups):\n",
    "        ages = np.zeros(len(group),dtype=float)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            gender = getGender(timeSeries)\n",
    "            ages[i] = 1 if gender >0 else -1\n",
    "        plt.hist(ages,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('User Count')\n",
    "        plt.xlabel('Age(years)')\n",
    "        plt.title(legends[g])\n",
    "        plt.show()\n",
    "        print(\"Age mean:{0:2f} STD:{1:2f}\".format(np.mean(ages),np.std(ages)))       \n",
    "        \n",
    "        \n",
    "def comboPlotPerUser(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 2,upperbound = 100,element_value=-1):\n",
    "    for g,group in enumerate(groups):\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "        combos_average = np.zeros(len(group),dtype=float)\n",
    "        for i,timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            combo = comboTracker(timeSeries)\n",
    "            filtered_combo = [hit for element, hit in combo if hit > lowerbound and hit < upperbound and element == element_value]\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "            combos_average[i] = sum(filtered_combo) / tweets_length[i]\n",
    "            \n",
    "        plt.hist(combos_average,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Post count')\n",
    "        plt.xlabel('Time (mins)')\n",
    "        plt.title(str(len(group)) + \" \"+legends[g] + \" people\")\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\"Average combo mean:{0:2f} STD:{1:2f}\".format(np.mean(combos_average),np.std(combos_average)))\n",
    "        \n",
    "        \n",
    "def comboPlot(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100, element_value=-1):\n",
    "    for g,group in enumerate(groups):\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "        combos = []\n",
    "        for i,timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            combo = comboTracker(timeSeries)\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "            combos += [hit for element, hit in combo if hit > lowerbound and hit < upperbound and element == element_value]\n",
    "        plt.hist(combos,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Post count')\n",
    "        plt.xlabel('Combos')\n",
    "        plt.title(str(len(group)) + \" \"+legends[g] + \" people\")\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\"Combo mean:{0:2f} STD:{1:2f}\".format(np.mean(combos),np.std(combos)))\n",
    "\n",
    "def flipPlotPerUser(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    print(\"Flip Durations of each flip\")\n",
    "    for g,group in enumerate(groups):\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "        flips_count = np.zeros(len(group),dtype=float)\n",
    "\n",
    "        for i,timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            flips = getFlips(timeSeries)\n",
    "            delta_times = getFlipsDuration(timeSeries, flips)\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "            flips_count[i] = np.sum((delta_times < upperbound) & (delta_times > lowerbound)) / tweets_length[i]\n",
    "        plt.hist(flips_count,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('People')\n",
    "        plt.xlabel('Flips / Tweets')\n",
    "        plt.title(str(len(group)) + \" \"+legends[g] + \" people\")\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\"Flips count mean:{0:2f} STD:{1:2f}\".format(np.mean(flips_count),np.std(flips_count)))\n",
    "\n",
    "\n",
    "def countPlotPerUser(groups,f, method=\"first\", bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    for g,group in enumerate(groups):\n",
    "        group = groupFilter(group)\n",
    "        counts = np.zeros(len(group),dtype=float)\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            if method is None:\n",
    "                http_count = f(timeSeries)\n",
    "            else:\n",
    "\n",
    "                http_count = f(timeSeries,method)\n",
    "            average_count = np.sum(http_count) / timeSeries.shape[0]\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "            counts[i] =  average_count\n",
    "        counts = counts[np.isfinite(counts)]\n",
    "        counts = counts[(counts>lowerbound) & (counts<upperbound)]\n",
    "        counts = reject_outliers(counts)\n",
    "        plt.hist(counts,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('people')\n",
    "        plt.xlabel('specific post / total post ')\n",
    "        plt.title(str(len(group)) + \" \" + legends[g] + \" people\")\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\" Mean:{0:2f} STD:{1:2f}\".format(np.mean(counts),np.std(counts)))\n",
    "    \n",
    "\n",
    "def flipDurationPlotPerUser(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    print(\"Flip Durations of each person\")\n",
    "    for g,group in enumerate(groups):\n",
    "        group = groupFilter(group)\n",
    "        delta_times = np.zeros(len(group),dtype=float)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            mean_deal_time = getFlipsDurationMean(timeSeries, lowerbound=0, upperbound=upperbound)\n",
    "            delta_times[i] = mean_deal_time\n",
    "        delta_times = delta_times[np.isfinite(delta_times)]\n",
    "        plt.hist(delta_times,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Person count')\n",
    "        plt.xlabel('Time (mins)')\n",
    "        plt.title(\"{} {} people \".format(len(group),legends[g]))\n",
    "        plt.show()\n",
    "        print(\"Time Duration mean:{0:2f} STD:{1:2f}\".format(np.mean(delta_times),np.std(delta_times)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def flipDurationPlot(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    print(\"Flip Durations of each flip\")\n",
    "    for g,group in enumerate(groups):\n",
    "        group = groupFilter(group)\n",
    "        delta_times = np.array([])\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "\n",
    "        for i,timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            flips = getFlips(timeSeries)\n",
    "            delta_times = np.concatenate((delta_times,getFlipsDuration(timeSeries, flips)))\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "        delta_times =delta_times[(delta_times < upperbound) & (delta_times > lowerbound)]\n",
    "        plt.hist(delta_times,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Flips count')\n",
    "        plt.xlabel('Time (mins)')\n",
    "        plt.title(str(len(group)) + \" \"+legends[g] + \" people\")\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\"Time Duration mean:{0:2f} STD:{1:2f}\".format(np.mean(delta_times),np.std(delta_times)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def durationPlotPerUser(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    print(\"Durations of each person\")\n",
    "    for g,group in enumerate(groups):\n",
    "        group = groupFilter(group)\n",
    "        delta_times = np.zeros(len(group),dtype=float)\n",
    "        for i, timeSeries in enumerate(group):\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            mean_deal_time = getMeanDeltaTime(timeSeries, upperbound=upperbound, lowerbound=lowerbound)\n",
    "            delta_times[i] = mean_deal_time\n",
    "        delta_times = delta_times[np.isfinite(delta_times)]\n",
    "        plt.hist(delta_times,color=colors[g], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Post count')\n",
    "        plt.xlabel('Time (mins)')\n",
    "        plt.title(legends[g])\n",
    "        plt.show()\n",
    "        print(\"Time Duration mean:{0:2f} STD:{1:2f}\".format(np.mean(delta_times),np.std(delta_times)))\n",
    "\n",
    "        \n",
    "        \n",
    "                \n",
    "        \n",
    "\n",
    "\n",
    "def durationPlot(groups, bins=100,legends = [\"BPD\", \"Normal\"], colors =['red', 'green'], lowerbound = 0,upperbound = 100):\n",
    "    print(\"Durations of each tweets pair\")\n",
    "    for i,group in enumerate(groups):\n",
    "        group = groupFilter(group)\n",
    "        delta_times = np.array([])\n",
    "        tweets_length = np.zeros(len(group),dtype=int)\n",
    "\n",
    "        for timeSeries in group:\n",
    "            timeSeries = cleanPost(timeSeries)\n",
    "            delta_times = np.concatenate((delta_times,timeSeries['dt'][:-1].values))\n",
    "            tweets_length[i] = timeSeries.shape[0]\n",
    "\n",
    "        delta_times =delta_times[(delta_times < upperbound) & (delta_times > lowerbound)]\n",
    "        plt.hist(delta_times,color=colors[i], bins = bins, edgecolor='none' )\n",
    "        plt.ylabel('Post count')\n",
    "        plt.xlabel('Time (mins)')\n",
    "        plt.title(legends[i])\n",
    "        plt.show()\n",
    "        print(\"Average size of total tweets: {} std:\".format(np.mean(tweets_length),np.std(tweets_length)))\n",
    "        print(\"Time Duration mean:{0:2f} STD:{1:2f}\".format(np.mean(delta_times),np.std(delta_times)))\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BPD_Polarties' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-c732de4f6128>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmix_Polarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetUsersPolarities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"patients\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"bb_mix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Transform raw tweets into timeSeries data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mBPDtimeSeries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeSeriesTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBPD_Polarties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mregular_timeSeries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeSeriesTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregular_Polarties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mbipolar_timeSeries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeSeriesTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbipolar_Polarties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BPD_Polarties' is not defined"
     ]
    }
   ],
   "source": [
    "#Fetching the data of BPD and random sampled Twitter user\n",
    "BPDP_Polarties =  getUsersPolarities(\"patients\",\"BPD_clean\")\n",
    "regular_Polarties =  getUsersPolarities(\"idea\",\"regularUser_en_fixed_emotion\")\n",
    "bipolar_Polarties = getUsersPolarities(\"patients\",\"bipolar_clean\")\n",
    "mix_Polarities = getUsersPolarities(\"patients\",\"bb_mix\")\n",
    "#Transform raw tweets into timeSeries data.\n",
    "BPDtimeSeries = timeSeriesTransform(BPD_Polarties) \n",
    "regular_timeSeries = timeSeriesTransform(regular_Polarties)\n",
    "bipolar_timeSeries = timeSeriesTransform(bipolar_Polarties)\n",
    "mix_timeSeries = timeSeriesTransform(mix)\n",
    "#Filter and clean the timeSeries data\n",
    "BPD_clean = groupFilter(BPDtimeSeries)\n",
    "regular_clean = random.sample(groupFilter(regular_timeSeries), len(BPD_clean))\n",
    "bipolar_clean = groupFilter(bipolar_timeSeries)\n",
    "mix_clean = groupFilter(mix_timeSeries)\n",
    "\n",
    "\n",
    "groups = [regular_clean,bipolar_clean, BPD_clean, mix_clean]\n",
    "colors=['g','b', 'r','y']\n",
    "legends = [\"Normal\", \"Bipolar\", \"BPD\",\"mix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the time of one flip, the Y-axis is the flips count\n",
    "\n",
    "flipDurationPlot(groups,legends=legends, colors=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the average flip time of user , the Y-axis is the user count\n",
    "flipDurationPlotPerUser(groups, upperbound=30,colors=[\"r\",\"g\",'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the flips/all-tweets ratio, the Y-axis is users count\n",
    "countPlotPerUser(groups, getFlips, method=None,colors=[\"r\",\"g\",'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the negative-post/all-tweets ratio, the Y-axis is users count\n",
    "countPlotPerUser(groups, negative_counter, method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the positive-post/all-tweets ratio, the Y-axis is users count\n",
    "\n",
    "countPlotPerUser(groups, positive_counter, method=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the first-pronoun/all-tweets ratio, the Y-axis is users count\n",
    "\n",
    "countPlotPerUser(groups, seriesContains) #First-pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the second-pronoun/all-tweets ratio, the Y-axis is users count\n",
    "\n",
    "countPlotPerUser(groups, seriesContains, method=\"second\") #second-pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the third-pronoun/all-tweets ratio, the Y-axis is users count\n",
    "\n",
    "countPlotPerUser(groups, seriesContains, method = \"third\") #Third-pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The X-axis is the amount of negative combos, the Y-axis is combo counts\n",
    "\n",
    "comboPlot(groups, upperbound=15, lowerbound=2, bins = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The 》-axis is the amount of positive combos, the Y-axis is combo counts\n",
    "\n",
    "comboPlot(groups, upperbound=15, lowerbound=2, bins = 20, element_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The X-axis is the ration of 3-or-higher negative-combo/all-tweets, the Y-axis is the user count \n",
    "comboPlotPerUser(groups,lowerbound=2,  upperbound=np.inf)   #   negative文章連發三次以上,    連發次數除以全部發文數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agePlot(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genderPlot(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
