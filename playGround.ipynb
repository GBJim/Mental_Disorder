{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Fetching, transformation and filtering\n",
    "\n",
    "\n",
    "def getLangRatio(cursor):\n",
    "    lang_ratios = {}\n",
    "    for tweet in cursor:\n",
    "        lang = 1 if tweet[\"lang\"] == \"en\" else 0\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        if user_id in lang_ratios:\n",
    "            lang_ratios[user_id].append(lang)\n",
    "        else:\n",
    "            lang_ratios[user_id] = [lang]\n",
    "    for user_id, ratio in lang_ratios.items():\n",
    "        lang_ratios[user_id] = np.sum(ratio) / len(ratio)\n",
    "    return lang_ratios\n",
    "                                   \n",
    "\n",
    "def getUsersTweets(dbName,collectionName, en_threshold=0.9):\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    lang_ratios = getLangRatio(cursor)\n",
    "\n",
    "    cursor = MongoClient(\"localhost\", 27017)[dbName][collectionName].find()\n",
    "    usersTweets = {}\n",
    "    for tweet in cursor:\n",
    "        userID = tweet[\"user\"][\"id\"]\n",
    "        if lang_ratios[userID] < en_threshold:\n",
    "            continue\n",
    "        #Processing emotions from Carlos' API\n",
    "        emotion =  tweet[\"emotion\"][\"groups\"][0][\"name\"]\n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]\n",
    "            \n",
    "        ambiguous = True if tweet['emotion']['ambiguous'] == 'yes' else False\n",
    "       \n",
    "        if len(tweet[\"emotion\"][\"groups\"]) > 1:\n",
    "            emotion_2 = tweet[\"emotion\"][\"groups\"][1][\"name\"]    \n",
    "        else:\n",
    "            emotion_2 = None\n",
    "        if tweet[\"polarity\"] == \"positive\":\n",
    "            polarity = 1\n",
    "        elif tweet[\"polarity\"] == \"negative\":\n",
    "            polarity = -1\n",
    "        else:\n",
    "            polarity = 0\n",
    "   \n",
    "            \n",
    "        date = tweet[\"created_at\"]\n",
    "        text = tweet['text']\n",
    "\n",
    "        if userID not in usersTweets:\n",
    "            usersTweets[userID] = {}\n",
    "        if date not in usersTweets[userID]:\n",
    "            usersTweets[userID][date] = {}\n",
    "            \n",
    "        usersTweets[userID][date]['text'] = text\n",
    "        usersTweets[userID][date]['polarity'] =  polarity\n",
    "        usersTweets[userID][date]['emotion'] =  emotion\n",
    "        usersTweets[userID][date]['emotion_2'] =  emotion_2\n",
    "        usersTweets[userID][date]['ambiguous'] =  ambiguous\n",
    "    return usersTweets\n",
    "\n",
    "\n",
    "\n",
    "def timeSeriesTransform(usersEmotions):\n",
    "    for userID in usersEmotions:\n",
    "        usersEmotions[userID] = pd.DataFrame.from_dict(usersEmotions[userID], orient='index').fillna(0)\n",
    "        usersEmotions[userID]['dt'] = np.zeros(usersEmotions[userID].shape[0],dtype=float)\n",
    "        usersEmotions[userID].loc[:-1,'dt'] = (usersEmotions[userID].index[1:].values - usersEmotions[userID].index[:-1].values).astype('timedelta64[s]') / np.timedelta64(60, 's')\n",
    "    return list(usersEmotions.values())\n",
    "\n",
    "\n",
    "def getHTTPRows(timeSeries):\n",
    "    count = 0\n",
    "    patterns = ['http://','https://']\n",
    "    conditions = timeSeries['text'].str.contains(patterns[0])\n",
    "    for pattern in patterns[1:]:\n",
    "        conditions = conditions | timeSeries['text'].str.contains(pattern)\n",
    "\n",
    "    return conditions.values\n",
    "\n",
    "def userFilter(group, spam_threshold=0.5,tweets_threshold=100):    #Spam and inactive user filter\n",
    "    new_group = []\n",
    "    for timeSeries in group:\n",
    "        http_rows = getHTTPRows(timeSeries)\n",
    "        average_http_count = np.sum(http_rows) / timeSeries.shape[0]\n",
    "        if (average_http_count < spam_threshold) and (timeSeries.shape[0] > tweets_threshold):\n",
    "            new_group.append(timeSeries)\n",
    "    return new_group\n",
    "\n",
    "class Group(object):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self, name, group=None, spam_threshold=0.5, tweets_threshold=100, **kwargs):\n",
    "        self.name = name\n",
    "\n",
    "        dbName  = kwargs.get(\"dbName\", None)\n",
    "        collectionName  = kwargs.get(\"collectionName\", None)\n",
    "        \n",
    "        if dbName is None or collectionName is None:\n",
    "            self.group = group\n",
    "        else:\n",
    "\n",
    "            self.group = userFilter(timeSeriesTransform(getUsersTweets(dbName,collectionName)), spam_threshold=spam_threshold, tweets_threshold=tweets_threshold)\n",
    "        \n",
    " \n",
    "        \n",
    "    def getTexts(self, tail_k = \"all\"):\n",
    "        if tail_k == \"all\":\n",
    "            return [\"\\n\".join(timeSeries[\"text\"].values) for timeSeries in self.group]\n",
    "        else:\n",
    "            return [\"\\n\".join(timeSeries[\"text\"].tail(tail_k).values) for timeSeries in self.group]\n",
    "\n",
    "    \n",
    "    def getName(self):\n",
    "        return self.name\n",
    "    def getSize(self):\n",
    "        return len(self.group)\n",
    "    def __repr__(self):\n",
    "        return repr(self.group)\n",
    "    def __add__(self, other):\n",
    "        return Group(self.name, self.group + other.group)\n",
    "    \n",
    "    def getGroup(self,tail_k=\"all\"):\n",
    "        if tail_k == \"all\":\n",
    "            return self.group\n",
    "        else:\n",
    "            return [timeSeries.tail(tail_k) for timeSeries in self.group]\n",
    "    \n",
    "    \n",
    "    def __iadd__(self, other):\n",
    "        self.group += other.group\n",
    "        return self    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "BPD_group_clean = Group(\"BPD\",dbName = \"patients\",collectionName=\"BPD_clean\")\n",
    "regular_group = Group(\"Random Samples\",dbName = \"idea\",collectionName=\"regularUser_en_fixed_emotion\")\n",
    "bipolar_group_clean = Group(\"Bipolar\",dbName =\"patients\", collectionName=\"bipolar_clean\")\n",
    "mix_group = Group(\"Mix\", dbName = \"patients\",collectionName=\"bb_mix\")\n",
    "\n",
    "\n",
    "BPD_all = BPD_group_clean + mix_group\n",
    "bipolar_all = bipolar_group_clean + mix_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getUserID(dbName, collectionName):\n",
    "    collection = MongoClient(\"localhost\", 27017)[dbName][collectionName]\n",
    "    cursor = collection.find()\n",
    "    user_ids = {}\n",
    "    for tweet in cursor:\n",
    "        lang = 1 if tweet[\"lang\"] == \"en\" else 0\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        if user_id not in filtered_id\n",
    "        user_ids.add(user_id)\n",
    "        if user_id in user_langs:\n",
    "            user_langs[user_id].append(lang)\n",
    "        else:\n",
    "            user_langs[user_id] = [lang]\n",
    "    return user_langs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getLangRatio(dbName, collectionName):\n",
    "    \n",
    "    collection = MongoClient(\"localhost\", 27017)[dbName][collectionName]\n",
    "    cursor = collection.find()\n",
    "    user_langs = {}\n",
    "    for tweet in cursor:\n",
    "        lang = 1 if tweet[\"lang\"] == \"en\" else 0\n",
    "        user_id = tweet[\"user\"][\"id\"]\n",
    "        if user_id in user_langs:\n",
    "            user_langs[user_id].append(lang)\n",
    "        else:\n",
    "            user_langs[user_id] = [lang]\n",
    "    return user_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_langs = getLangRatio(\"patients\", \"BPD_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BPD_lang_ratios = [(user_id, np.sum(langs_ratio)/len(langs_ratio)) for user_id, langs_ratio in user_langs.items()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3262241903 0.0\n",
      "944577823 0.119863013699\n",
      "269690229 0.220713609094\n",
      "2413555298 0.31308411215\n",
      "3324571407 0.32\n",
      "3263225837 0.333333333333\n",
      "3077233757 0.380952380952\n",
      "169951404 0.415136755339\n",
      "244021118 0.430107526882\n",
      "45229455 0.495652173913\n",
      "3194839751 0.5\n",
      "116439735 0.510220125786\n",
      "510585906 0.550855085509\n",
      "3227127058 0.551724137931\n",
      "374595521 0.571428571429\n",
      "2954272784 0.57215007215\n",
      "2292426456 0.6\n",
      "558473669 0.621212121212\n",
      "202200525 0.644128113879\n",
      "2936388081 0.654624277457\n",
      "49450953 0.700718525461\n",
      "2251489214 0.714285714286\n",
      "3228645394 0.717948717949\n",
      "3297759413 0.728155339806\n",
      "58007127 0.731600375822\n",
      "287681418 0.747753973739\n"
     ]
    }
   ],
   "source": [
    "BPD_lang_ratios = sorted(BPD_lang_ratios, key=lambda x: x[1])\n",
    "\n",
    "for user_id, en_ratio in BPD_lang_ratios:\n",
    "    if en_ratio < 0.75:\n",
    "        print(user_id, en_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933392432 0.0\n",
      "153294609 0.0172705722994\n",
      "3029977273 0.0310130944176\n",
      "2827792882 0.0769230769231\n",
      "809571888 0.0880503144654\n",
      "2499362502 0.127009646302\n",
      "3367338663 0.173913043478\n",
      "1229003286 0.185840707965\n",
      "2286202992 0.188405797101\n",
      "2984096968 0.2\n",
      "3120472413 0.210365853659\n",
      "504686644 0.261935483871\n",
      "2921022655 0.317073170732\n",
      "368501489 0.354838709677\n",
      "553466344 0.385796545106\n",
      "192116423 0.39165085389\n",
      "3182719408 0.4\n",
      "1962364130 0.407407407407\n",
      "2425691041 0.425634824667\n",
      "2600004696 0.439393939394\n",
      "3041204445 0.475409836066\n",
      "70032674 0.480043149946\n",
      "3238987287 0.5\n",
      "3076152329 0.539748953975\n",
      "1015217155 0.558333333333\n",
      "962084311 0.561849710983\n",
      "1247445650 0.591133004926\n",
      "1408777951 0.593103448276\n",
      "206804977 0.608804402201\n",
      "88995343 0.612752721617\n",
      "29587967 0.61733615222\n",
      "348873140 0.617647058824\n",
      "582230868 0.624203821656\n",
      "101816365 0.625\n",
      "2751352106 0.636363636364\n",
      "2950280698 0.645161290323\n",
      "770070936 0.646706586826\n",
      "102816119 0.655367231638\n",
      "28725721 0.661290322581\n",
      "3307369534 0.666666666667\n",
      "2531462476 0.666666666667\n",
      "3322592482 0.669491525424\n",
      "457159794 0.69587628866\n",
      "52583796 0.696078431373\n",
      "2376258739 0.698305084746\n",
      "799930532 0.705882352941\n",
      "3190271468 0.706013363029\n",
      "595742207 0.709168184578\n",
      "24506740 0.718177757928\n",
      "2928946654 0.719259259259\n",
      "3139943185 0.725663716814\n",
      "2951011342 0.72602739726\n",
      "2508649198 0.727272727273\n",
      "2820185271 0.730538922156\n",
      "387551744 0.732994923858\n",
      "482865387 0.7375\n",
      "243270552 0.738339920949\n",
      "2971884153 0.739682539683\n",
      "2332903002 0.742807323452\n"
     ]
    }
   ],
   "source": [
    "user_langs = getLangRatio(\"patients\", \"bipolar_clean\")\n",
    "bipolar_lang_ratios = [(user_id, np.sum(langs_ratio)/len(langs_ratio)) for user_id, langs_ratio in user_langs.items()]\n",
    "bipolar_lang_ratios = sorted(bipolar_lang_ratios, key=lambda x: x[1])\n",
    "\n",
    "for user_id, en_ratio in bipolar_lang_ratios:\n",
    "    if en_ratio < 0.75:\n",
    "        print(user_id, en_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang_ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
