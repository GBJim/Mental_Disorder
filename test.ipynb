{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "%matplotlib inline\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=random_state)\n",
    "\n",
    "# Run classifier\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(),\n",
    "    y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve for each class\n",
    "plt.clf()\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "         label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "               ''.format(average_precision[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i],\n",
    "             label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                   ''.format(i, average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "collection = MongoClient(\"localhost\", 27017)[\"idea\"][\"emotion\"]\n",
    "tweets = []\n",
    "for tweet in collection.find():\n",
    "    emotion = tweet[\"emotion\"][\"groups\"][0][\"name\"]\n",
    "    if emotion ==  \"anticipation\":\n",
    "        tweets.append(tweet)\n",
    "    if len(tweets) > 50:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets[4][\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Author: Virgile Fritsch <virgile.fritsch@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Get data\n",
    "X1 = load_boston()['data'][:, [8, 10]]  # two clusters\n",
    "X2 = load_boston()['data'][:, [5, 12]]  # \"banana\"-shaped\n",
    "\n",
    "# Define \"classifiers\" to be used\n",
    "classifiers = {\n",
    "    \"Empirical Covariance\": EllipticEnvelope(support_fraction=1.,\n",
    "                                             contamination=0.261),\n",
    "    \"Robust Covariance (Minimum Covariance Determinant)\":\n",
    "    EllipticEnvelope(contamination=0.261),\n",
    "    \"OCSVM\": OneClassSVM(nu=0.261, gamma=0.05)}\n",
    "colors = ['m', 'g', 'b']\n",
    "legend1 = {}\n",
    "legend2 = {}\n",
    "\n",
    "# Learn a frontier for outlier detection with several classifiers\n",
    "xx1, yy1 = np.meshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "xx2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    plt.figure(1)\n",
    "    clf.fit(X1)\n",
    "    Z1 = clf.decision_function(np.c_[xx1.ravel(), yy1.ravel()])\n",
    "    Z1 = Z1.reshape(xx1.shape)\n",
    "    legend1[clf_name] = plt.contour(\n",
    "        xx1, yy1, Z1, levels=[0], linewidths=2, colors=colors[i])\n",
    "    plt.figure(2)\n",
    "    clf.fit(X2)\n",
    "    Z2 = clf.decision_function(np.c_[xx2.ravel(), yy2.ravel()])\n",
    "    Z2 = Z2.reshape(xx2.shape)\n",
    "    legend2[clf_name] = plt.contour(\n",
    "        xx2, yy2, Z2, levels=[0], linewidths=2, colors=colors[i])\n",
    "\n",
    "legend1_values_list = list( legend1.values() )\n",
    "legend1_keys_list = list( legend1.keys() )\n",
    "\n",
    "# Plot the results (= shape of the data points cloud)\n",
    "plt.figure(1)  # two clusters\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='black')\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "plt.annotate(\"several confounded points\", xy=(24, 19),\n",
    "             xycoords=\"data\", textcoords=\"data\",\n",
    "             xytext=(13, 10), bbox=bbox_args, arrowprops=arrow_args)\n",
    "plt.xlim((xx1.min(), xx1.max()))\n",
    "plt.ylim((yy1.min(), yy1.max()))\n",
    "plt.legend((legend1_values_list[0].collections[0],\n",
    "            legend1_values_list[1].collections[0],\n",
    "            legend1_values_list[2].collections[0]),\n",
    "           (legend1_keys_list[0], legend1_keys_list[1], legend1_keys_list[2]),\n",
    "           loc=\"upper center\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))\n",
    "plt.ylabel(\"accessibility to radial highways\")\n",
    "plt.xlabel(\"pupil-teatcher ratio by town\")\n",
    "\n",
    "legend2_values_list = list( legend2.values() )\n",
    "legend2_keys_list = list( legend2.keys() )\n",
    "\n",
    "plt.figure(2)  # \"banana\" shape\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='black')\n",
    "plt.xlim((xx2.min(), xx2.max()))\n",
    "plt.ylim((yy2.min(), yy2.max()))\n",
    "plt.legend((legend2_values_list[0].collections[0],\n",
    "            legend2_values_list[1].collections[0],\n",
    "            legend2_values_list[2].collections[0]),\n",
    "           (legend2_values_list[0], legend2_values_list[1], legend2_values_list[2]),\n",
    "           loc=\"upper center\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))\n",
    "plt.ylabel(\"% lower status of the population\")\n",
    "plt.xlabel(\"average number of rooms per dwelling\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "n_samples = 125\n",
    "n_outliers = 25\n",
    "n_features = 2\n",
    "\n",
    "# generate data\n",
    "gen_cov = np.eye(n_features)\n",
    "gen_cov[0, 0] = 2.\n",
    "X = np.dot(np.random.randn(n_samples, n_features), gen_cov)\n",
    "# add some outliers\n",
    "outliers_cov = np.eye(n_features)\n",
    "outliers_cov[np.arange(1, n_features), np.arange(1, n_features)] = 7.\n",
    "X[-n_outliers:] = np.dot(np.random.randn(n_outliers, n_features), outliers_cov)\n",
    "\n",
    "# fit a Minimum Covariance Determinant (MCD) robust estimator to data\n",
    "robust_cov = MinCovDet().fit(X)\n",
    "\n",
    "# compare estimators learnt from the full data set with true parameters\n",
    "emp_cov = EmpiricalCovariance().fit(X)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(hspace=-.1, wspace=.4, top=.95, bottom=.05)\n",
    "\n",
    "# Show data set\n",
    "subfig1 = plt.subplot(3, 1, 1)\n",
    "inlier_plot = subfig1.scatter(X[:, 0], X[:, 1],\n",
    "                              color='black', label='inliers')\n",
    "outlier_plot = subfig1.scatter(X[:, 0][-n_outliers:], X[:, 1][-n_outliers:],\n",
    "                               color='red', label='outliers')\n",
    "subfig1.set_xlim(subfig1.get_xlim()[0], 11.)\n",
    "subfig1.set_title(\"Mahalanobis distances of a contaminated data set:\")\n",
    "\n",
    "# Show contours of the distance functions\n",
    "xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n",
    "                     np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\n",
    "zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "mahal_emp_cov = emp_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n",
    "                                  cmap=plt.cm.PuBu_r,\n",
    "                                  linestyles='dashed')\n",
    "\n",
    "mahal_robust_cov = robust_cov.mahalanobis(zz)\n",
    "mahal_robust_cov = mahal_robust_cov.reshape(xx.shape)\n",
    "robust_contour = subfig1.contour(xx, yy, np.sqrt(mahal_robust_cov),\n",
    "                                 cmap=plt.cm.YlOrBr_r, linestyles='dotted')\n",
    "\n",
    "subfig1.legend([emp_cov_contour.collections[1], robust_contour.collections[1],\n",
    "                inlier_plot, outlier_plot],\n",
    "               ['MLE dist', 'robust dist', 'inliers', 'outliers'],\n",
    "               loc=\"upper right\", borderaxespad=0)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# Plot the scores for each point\n",
    "emp_mahal = emp_cov.mahalanobis(X - np.mean(X, 0)) ** (0.33)\n",
    "subfig2 = plt.subplot(2, 2, 3)\n",
    "subfig2.boxplot([emp_mahal[:-n_outliers], emp_mahal[-n_outliers:]], widths=.25)\n",
    "subfig2.plot(1.26 * np.ones(n_samples - n_outliers),\n",
    "             emp_mahal[:-n_outliers], '+k', markeredgewidth=1)\n",
    "subfig2.plot(2.26 * np.ones(n_outliers),\n",
    "             emp_mahal[-n_outliers:], '+k', markeredgewidth=1)\n",
    "subfig2.axes.set_xticklabels(('inliers', 'outliers'), size=15)\n",
    "subfig2.set_ylabel(r\"$\\sqrt[3]{\\rm{(Mahal. dist.)}}$\", size=16)\n",
    "subfig2.set_title(\"1. from non-robust estimates\\n(Maximum Likelihood)\")\n",
    "plt.yticks(())\n",
    "\n",
    "robust_mahal = robust_cov.mahalanobis(X - robust_cov.location_) ** (0.33)\n",
    "subfig3 = plt.subplot(2, 2, 4)\n",
    "subfig3.boxplot([robust_mahal[:-n_outliers], robust_mahal[-n_outliers:]],\n",
    "                widths=.25)\n",
    "subfig3.plot(1.26 * np.ones(n_samples - n_outliers),\n",
    "             robust_mahal[:-n_outliers], '+k', markeredgewidth=1)\n",
    "subfig3.plot(2.26 * np.ones(n_outliers),\n",
    "             robust_mahal[-n_outliers:], '+k', markeredgewidth=1)\n",
    "subfig3.axes.set_xticklabels(('inliers', 'outliers'), size=15)\n",
    "subfig3.set_ylabel(r\"$\\sqrt[3]{\\rm{(Mahal. dist.)}}$\", size=16)\n",
    "subfig3.set_title(\"2. from robust estimates\\n(Minimum Covariance Determinant)\")\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# Example settings\n",
    "n_samples = 200\n",
    "outliers_fraction = 0.25\n",
    "clusters_separation = [0, 1, 2]\n",
    "\n",
    "# define two outlier detection tools to be compared\n",
    "classifiers = {\n",
    "    \"One-Class SVM\": svm.OneClassSVM(nu=0.95 * outliers_fraction + 0.05,\n",
    "                                     kernel=\"rbf\", gamma=0.1),\n",
    "    \"robust covariance estimator\": EllipticEnvelope(contamination=.1)}\n",
    "\n",
    "# Compare given classifiers under given settings\n",
    "xx, yy = np.meshgrid(np.linspace(-7, 7, 500), np.linspace(-7, 7, 500))\n",
    "n_inliers = int((1. - outliers_fraction) * n_samples)\n",
    "n_outliers = int(outliers_fraction * n_samples)\n",
    "ground_truth = np.ones(n_samples, dtype=int)\n",
    "ground_truth[-n_outliers:] = 0\n",
    "\n",
    "# Fit the problem with varying cluster separation\n",
    "for i, offset in enumerate(clusters_separation):\n",
    "    np.random.seed(42)\n",
    "    # Data generation\n",
    "    X1 = 0.3 * np.random.randn(0.5 * n_inliers, 2) - offset\n",
    "    X2 = 0.3 * np.random.randn(0.5 * n_inliers, 2) + offset\n",
    "    X = np.r_[X1, X2]\n",
    "    # Add outliers\n",
    "    X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]\n",
    "\n",
    "    # Fit the model with the One-Class SVM\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "        # fit the data and tag outliers\n",
    "        clf.fit(X)\n",
    "        y_pred = clf.decision_function(X).ravel()\n",
    "        threshold = stats.scoreatpercentile(y_pred,\n",
    "                                            100 * outliers_fraction)\n",
    "        y_pred = y_pred > threshold\n",
    "        n_errors = (y_pred != ground_truth).sum()\n",
    "        # plot the levels lines and the points\n",
    "        Z = clf.(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        subplot = plt.subplot(1, 2, i + 1)\n",
    "        subplot.set_title(\"Outlier detection\")\n",
    "        subplot.contourf(xx, yy, Z, levels=np.linspace(Z.min(), threshold, 7),\n",
    "                         cmap=plt.cm.Blues_r)\n",
    "        a = subplot.contour(xx, yy, Z, levels=[threshold],\n",
    "                            linewidths=2, colors='red')\n",
    "        subplot.contourf(xx, yy, Z, levels=[threshold, Z.max()],\n",
    "                         colors='orange')\n",
    "        b = subplot.scatter(X[:-n_outliers, 0], X[:-n_outliers, 1], c='white')\n",
    "        c = subplot.scatter(X[-n_outliers:, 0], X[-n_outliers:, 1], c='black')\n",
    "        subplot.axis('tight')\n",
    "        subplot.legend(\n",
    "            [a.collections[0], b, c],\n",
    "            ['learned decision function', 'true inliers', 'true outliers'],\n",
    "            prop=matplotlib.font_manager.FontProperties(size=11))\n",
    "        subplot.set_xlabel(\"%d. %s (errors: %d)\" % (i + 1, clf_name, n_errors))\n",
    "        subplot.set_xlim((-7, 7))\n",
    "        subplot.set_ylim((-7, 7))\n",
    "    plt.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.linspace(-7, 7, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 1000\n",
    "x = np.linspace(0, 10, num)\n",
    "y = np.exp(x)\n",
    "\n",
    "# Add some non-stationary noise that's hard to see without de-trending\n",
    "noise = 100 * np.exp(0.2 * x) * np.random.normal(0, 1, num)\n",
    "y += noise\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10*np.pi, 10*np.pi, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " plt.plot(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.fft.fft(x))\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    ">>> # Number of samplepoints\n",
    ">>> N = 600\n",
    ">>> # sample spacing\n",
    ">>> T = 1.0 / 800.0\n",
    ">>> x = np.linspace(0.0, N*T, N)\n",
    ">>> y = 0.5*np.sin(50.0 * 2.0*np.pi*x) + 0.5*np.sin(65.0 * 5.0*np.pi*x)\n",
    ">>> yf = fft(y)\n",
    ">>> xf = np.linspace(0.0, 1.0/(2.0*T), N)\n",
    ">>> import matplotlib.pyplot as plt\n",
    ">>> plt.plot(xf, 2.0/N * np.abs(yf))\n",
    ">>> plt.grid()\n",
    ">>> plt.show()\n",
    "np.amax(2.0/N * np.abs(yf[0:N/2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x,fft(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> import matplotlib.pyplot as plt\n",
    ">>> t = np.arange(256)\n",
    ">>> sp = np.fft.fft(np.sin(t))\n",
    ">>> freq = np.fft.fftfreq(t.shape[-1])\n",
    ">>> plt.plot(freq, np.abs(sp))\n",
    "\n",
    "freq[freq.size/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.arange(256)\n",
    ">>> sp = np.fft.fft(np.sin(t))\n",
    ">>> freq = np.fft.fftfreq(t.shape[-1])\n",
    ">>> plt.plot(freq, sp.real, freq, sp.imag)\n",
    "[<matplotlib.lines.Line2D object at 0x...>, <matplotlib.lines.Line2D object at 0x...>]\n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('140.114.77.23', 27017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client['idea']['test'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2720d1b020b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idea'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "x = client['idea']['test'].find_one()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
